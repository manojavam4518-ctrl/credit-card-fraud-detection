This project develops a system designed to automatically identify and flag fraudulent credit card transactions, helping financial institutions prevent financial losses and protect customers, where the central challenge of this task is dealing with extremely unbalanced data, as nearly all transactions are legitimate, and fraudulent ones are very rare, utilizing a public dataset containing anonymized transaction data for modeling.The primary goal was to build a machine learning model that can accurately distinguish between genuine transactions, which form the majority, and fraudulent transactions, which are the minority, while a major focus was implementing techniques to ensure the model could learn from the very few fraud cases available, preventing it from simply ignoring fraud entirely, and finally, performance was carefully assessed using metrics appropriate for this kind of problem, prioritizing catching actual fraud rather than just achieving high overall accuracy.The project followed a standard data science workflow to ensure the resulting model was robust and reliable; the transaction data, which includes features like transaction amount and time, was first prepared for modeling, and all data was scaled to ensure that no single feature, such as the transaction amount, could unfairly dominate the training process just because it had larger numerical values.Because fraud cases were extremely rare, a technique called SMOTE, which stands for Synthetic Minority Over-sampling Technique, was applied, which effectively creates synthetic or artificial examples of fraud cases based on the existing small sample of real fraud data, thereby balancing the dataset, making it easier for the machine learning models to properly learn the characteristics of a fraudulent transaction.We compared three different classification algorithms to determine which one performed best at detecting fraud: Logistic Regression, which is a simpler, baseline model; Random Forest, which is an ensemble of many decision trees; and XGBoost, which is a highly efficient and powerful gradient boosting algorithm, and this advanced XGBoost model was further optimized by using Optuna, an automatic hyperparameter optimization tool, to fine-tune its internal settings and achieve the best possible performance.Since simple accuracy is misleading for this type of data, because a model that guesses "no fraud" every time would still be over 99 percent accurate, we focused on specialized metrics, where the ROC Curve, which stands for Receiver Operating Characteristic, and the Confusion Matrix were used to measure the model's effectiveness in balancing two critical needs: maximizing the number of frauds caught, which is called Recall, and minimizing the number of legitimate transactions falsely flagged as fraud, which is called Precision.The following tools were essential for the development and execution of this project: Python as the programming language; Pandas and NumPy for data handling and numerical operations; Scikit-learn for standard machine learning algorithms and evaluation tools; XGBoost as the high-performance classification model; Imbalanced-learn, which contains the SMOTE technique; and Optuna for hyperparameter optimization.For code assistance, this project benefited from Generative AI assistance, specifically using Google Gemini and ChatGPT, primarily for drafting code structure, refining explanations, and debugging technical errors, and the project uses the Credit Card Fraud Detection dataset hosted on Kaggle.
